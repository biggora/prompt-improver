# Prompt Improver

A Next.js web application that helps users optimize their prompts using AI analysis. Transform your prompts for better results across different domains.

<img width="3676" height="1726" alt="ui" src="https://github.com/user-attachments/assets/9d7d181f-50fe-498c-b6b7-4903a26527e0" />

## ğŸš€ Features

- **Multi-Provider Support**: Choose from Anthropic Claude, OpenAI, Google Gemini, Zhipu AI, or local Ollama
- **Domain-Specific Optimization**: Choose from 5 specialized domains (Programming, Writing, Research, Business, Data Analysis)
- **AI-Powered Analysis**: Identifies issues and generates comprehensive improvements
- **Interactive Results**: See exactly what was changed and why
- **Prompt History**: Browse and search your previous prompt improvements
- **Easy Copy-to-Clipboard**: Instantly copy your optimized prompts
- **Responsive Design**: Works seamlessly on desktop, tablet, and mobile
- **Modern UI**: Clean, gradient-based dark theme with smooth interactions

## ğŸ› ï¸ Tech Stack

- **Framework**: Next.js 16 with Turbopack
- **Frontend**: React 19 with TypeScript
- **Styling**: Tailwind CSS
- **Icons**: Lucide React
- **AI Integration**: Vercel AI SDK with multiple providers
- **Database**: IndexedDB (browser-based storage)
- **Package Manager**: pnpm

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/prompt-improver.git
cd prompt-improver

# Install dependencies
pnpm install

# Copy environment file
cp .env.example .env

# Add your API keys to .env file

# Start development server
pnpm run dev
```

## ğŸ³ Docker Support

The application is containerized for easy deployment and local testing.

### Prerequisites

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

### Running with Docker

1. **Configure Environment**: Ensure your `.env` file contains the necessary API keys.
2. **Build and Start**:
   ```bash
   docker compose up -d --build
   ```
3. **Access the App**: Open `http://localhost:3000` in your browser.

### Docker Commands

- **Stop Containers**: `docker compose down`
- **View Logs**: `docker compose logs -f`
- **Rebuild**: `docker compose up -d --build`

## ğŸ¯ Usage

1. **Choose AI Provider**: Select from Anthropic Claude, OpenAI, Google Gemini, Zhipu AI, or local Ollama
2. **Select Model**: Choose the specific AI model you want to use
3. **Select Domain(s)**: Choose one or more domains that match your use case
4. **Enter Your Prompt**: Paste your original prompt in the textarea
5. **Click "Improve Prompt"**: Let the AI analyze and optimize your prompt
6. **Review Results**: See the issues found and improvements made
7. **Copy & Use**: Copy the improved prompt to your clipboard

## ğŸ”§ Supported Domains

### ğŸ’» Programming

- Code generation and debugging
- Architecture and design patterns
- Code review and optimization

### âœï¸ Writing

- Creative writing and copywriting
- Content creation and editing
- Technical documentation

### ğŸ”¬ Research

- Academic papers and analysis
- Data investigation and reports
- Literature reviews

### ğŸ’¼ Business

- Strategy and planning
- Professional communication
- Project management

### ğŸ“Š Data Analysis

- Statistical analysis
- Data visualization
- Insights and reporting

## ğŸ”’ API Configuration

Configure API keys via environment variables for security.

Copy the example environment file:

```bash
cp .env.example .env
```

Edit the `.env` file with your API keys:

```bash
# API Keys (server-side only - no prefix needed)
ANTHROPIC_API_KEY=sk-ant-api03-...
OPENAI_API_KEY=sk-...
ZHIPU_API_KEY=...
GEMINI_API_KEY=...

# Ollama configuration (client-side - needs NEXT_PUBLIC_ prefix)
NEXT_PUBLIC_OLLAMA_BASE_URL=http://localhost:11434
```

### AI Providers

#### ğŸ¤– Anthropic Claude

- **Models**: Claude Sonnet 4, Claude 3.5 Sonnet, Claude 3.5 Haiku
- **Requirements**: Anthropic API key
- **Setup**: Get API key from [Anthropic Console](https://console.anthropic.com/)

#### ğŸ§  OpenAI

- **Models**: GPT-4o, GPT-4o Mini, GPT-4 Turbo, GPT-3.5 Turbo
- **Requirements**: OpenAI API key
- **Setup**: Get API key from [OpenAI Platform](https://platform.openai.com/)

#### âœ¨ Google Gemini

- **Models**: Gemini 2.5 Flash, Gemini 2.5 Pro, Gemini 2.0 Flash
- **Requirements**: Gemini API key
- **Setup**: Get API key from [Google AI Studio](https://aistudio.google.com/)

#### ğŸŒ Zhipu AI (Z.AI)

- **Models**: GLM-4 Plus, GLM-4, GLM-4 Flash, GLM-4 Air
- **Requirements**: Zhipu API key
- **Setup**: Get API key from [Zhipu AI Platform](https://open.bigmodel.cn/)

#### ğŸ¦™ Ollama (Local)

- **Models**: All local Ollama models
- **Requirements**: Local Ollama installation
- **Setup**:
  1. Install Ollama from [ollama.ai](https://ollama.ai/)
  2. Start Ollama service
  3. Pull models: `ollama pull llama2` or any other model
  4. Configure optional custom URL in `.env`

## ğŸ—ï¸ Project Structure

```
prompt-improver/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ improve/route.ts    # AI improvement endpoint
â”‚   â”‚   â””â”€â”€ validate/route.ts   # API key validation
â”‚   â”œâ”€â”€ layout.tsx              # Root layout
â”‚   â””â”€â”€ page.tsx                # Main page
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ prompt-improver.tsx     # Main component
â”‚   â”œâ”€â”€ prompt-history.tsx      # History component
â”‚   â””â”€â”€ provider-selector.tsx   # Provider/model selector
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ ai-service.ts           # AI service & providers
â”‚   â”œâ”€â”€ database.ts             # IndexedDB storage
â”‚   â”œâ”€â”€ prompts.ts              # System prompts
â”‚   â””â”€â”€ types.ts                # TypeScript types
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ package.json                # Dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸš§ Current Status & Roadmap

### âœ… Completed

- Multi-provider AI integration (Anthropic, OpenAI, Gemini, Zhipu, Ollama)
- Domain-specific prompt optimization
- Modern UI with Tailwind CSS dark theme
- Prompt history with search functionality
- Copy-to-clipboard functionality
- Responsive design for all devices
- Error handling and loading states

### ğŸ“‹ Planned

- [ ] Unit and integration tests
- [ ] E2E testing
- [ ] Enhanced rate limiting
- [ ] Advanced input validation
- [ ] Export/import prompt history
- [ ] API key validation UI

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the ISC License - see the package.json file for details.

## ğŸ³ Docker Deployment

The project includes a multi-stage Docker configuration optimized for Next.js.

### Core Files

- `Dockerfile`: Multi-stage build process (deps, builder, runner).
- `docker-compose.yml`: Service definition and port mapping.
- `.dockerignore`: Excludes unnecessary files from the build context.

### Build Details

- **Base Image**: `node:22-alpine`
- **PackageManager**: `pnpm`
- **Output Mode**: `standalone` (for minimized image size)
- **User**: Runs as non-root `nextjs` user for security.

## ğŸ”— Resources

- [Anthropic Claude API Documentation](https://docs.anthropic.com/)
- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Google Gemini API Documentation](https://ai.google.dev/docs)
- [Vercel AI SDK Documentation](https://sdk.vercel.ai/docs)
- [Next.js Documentation](https://nextjs.org/docs)
- [Tailwind CSS Documentation](https://tailwindcss.com/docs)

---

Built with â¤ï¸ for better prompt engineering
